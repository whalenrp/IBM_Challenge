import sys
import math
from AbstractLearner import AbstractLearner
from random import Random

class BaggingLearner(AbstractLearner):
	"""
	Derived class implementation of AbstractLearner. This class implements the learn() 
	and classify() functions using a Bagging approach
	"""

	class Node:
		"""
		Container class for storing the percentage of Trues found at this node in the
		training data, the variable this node splits over (splitColumn), 
		the value that the variable splits around for the given column 
		(i.e. myRow[splitColumn] < splitValue ), and the left and right child themselves.
		"""
		def __init__(self, percentTrue, splitColumn, splitValue, leftChild, rightChild):
			self.percentTrue = percentTrue
			self.splitColumn = splitColumn
			self.splitValue  = splitValue
			self.leftChild   = leftChild
			self.rightSplit  = rightChild
		
	def __init__(self, trainingInputFile, testInputFile, isMachineReadable, outputFile):
		AbstractLearner.__init__(self, trainingInputFile, testInputFile, 
			isMachineReadable, outputFile)
		self.forest = list()

		# The tree-building algorithm will halt when it sees a node with 
		# RECURSION_SPLIT_THRESHOLD number of items in it.
		self.RECURSION_SPLIT_THRESHOLD = math.sqrt(len(self.trainingData))

		# The number of trees generated by the bagging algorithm.
		self.NUMBER_OF_TREES = len(self.trainingData)/3

	def learn(self):
		"""
		Creates a classification model based on data held in the AbstractLearner's 
		trainingData list-of-lists
		"""

		del self.forest[:] # Empty the list of previous contents
		randomGen = Random()
		numRows = len(self.trainingData)
		for _ in range(self.NUMBER_OF_TREES): # The number of random trees in forest
			data = list()
			for _ in range(numRows): # Generate the random tree itself
				randomNum = randomGen.randrange(numRows)
				data.append(self.trainingData[randomNum])
			self.forest.append(
				self.makeTree(data, range(len(self.trainingData)),self.RECURSION_SPLIT_THRESHOLD))
#		self.makeTree(self.trainingData, range(len(self.trainingData)), self.RECURSION_SPLIT_THRESHOLD)
		

	def classify(self):
		"""
		Based on the classification model generated by learn(), this function will read from
		the testData list-of-lists in AbstractLearner and output the prediction for each 
		variable
		"""
		print "Function not yet Defined"
		sys.exit(0)


		
	def makeTree(self, data, rangeOfRows, recursionThreshold):
		"""
		Returns a tree created from the given data.
		"""

		# Base case. If we have fewer than recursionThreshold rows to split around,
		# terminate.
		if len(rangeOfRows) <= recursionThreshold:
			return None

		# bestOverallSplit contains (column, splitValue, number of Trues)
		(splitColumn, splitValue, numTrues) = self.findBestSplit(data, rangeOfRows)

		# Base case. If there is no good column to split around or
		# no more splitting should be done, terminate
		if numTrues == 0 or numTrues == len(rangeOfRows):
			return None

		print(splitColumn, splitValue, numTrues)

		# Build the range of training rows that will go left or right
		leftSplit = list()
		rightSplit = list()
		for i in rangeOfRows:
			if data[i][splitColumn] < splitValue:
				leftSplit.append(i)
			else:
				rightSplit.append(i)

		# If the split puts all data into either the left or the right child,
		# we aren't actually splitting. Terminate, since no good split was found 
		# to be better than random.
		if len(leftSplit) == 0 or len(rightSplit) == 0:
			return None
		
		return self.Node(float(numTrues)/ len(rangeOfRows), # Percentage true
					splitColumn, # Column to split the data around for children
					splitValue, # Value to split on splitColumn
					self.makeTree(data, leftSplit, recursionThreshold), # recurse for left child
					self.makeTree(data, rightSplit, recursionThreshold)) # recurse for right child


	def findBestSplit(self, data, rangeOfRows):
		"""
		Helper function that calculates the best variable to split around and
		what value to split on. This function also returns the number of Trues
		in the result. 
		Returns (splitIndex, splitValue, trueCount)
		"""
		# Pull out only the data that is important for this node
		nodeData = [data[x] for x in rangeOfRows]
		
		# transpose data
		columns = [list(a) for a in zip(*nodeData)]

		# Get the number of trues from the last column
		totalTrueCount = len(filter(lambda x: x, columns[-1]))
		
		self.printListofLists(columns)
		
		# Zip up the continuously valued variables with their classifications and
		# sort by the continuous variables. Then, find the best split of the row
		# for each variable and decide to split on the best variable overall.
		bestSplitOverall = (-1, 0, 0) # (column, splitValue, score)
		for i in range(len(columns)-1):
			tuplesList = sorted(zip(columns[i], columns[-1]))

			# First, calculate the "sum" of this row of entries from the 
			# number of Trues and Falses in the row. We will use this
			# value to check if the majority of Trues or falses are to the
			# left or right of a possible split.
			totalRowValue = 0
			for mDataPoint in tuplesList:
				totalRowValue += 1 if mDataPoint[1] else -1

			# loop over the tuples, but only consider splits
			# that are between different numbers. (ie. don't 
			# split between two equal values)
			bestSplit = (0, abs(totalRowValue)) # The best split so far is tracked by (index, score)
			curScore = 0
			prevElement = tuplesList[0][0]
			for j in range(1, len(tuplesList)):
				curScore += 1 if tuplesList[j-1][1] else -1
				scoreRightOfSplit = totalRowValue - curScore

				# If we are looking at a new element and the current score is better
				# than any previous score, update our best score
				if tuplesList[j][0] != prevElement and abs(curScore - scoreRightOfSplit) > bestSplit[1]:
					bestSplit = (j, abs(curScore - scoreRightOfSplit))
				prevElement = tuplesList[j][0]

			# Set the bestSplitOverall if this is our first iteration
			# so we have a value to beat
			if i == 0:
				bestSplitOverall = (0, tuplesList[bestSplit[0]][0], bestSplit[1])
			elif bestSplit[1] > bestSplitOverall[2]:
				bestSplitOverall = (i, tuplesList[bestSplit[0]][0], bestSplit[1])
			#print(tuplesList, bestSplit, bestSplitOverall)
		return (bestSplitOverall[0], bestSplitOverall[1], totalTrueCount)
